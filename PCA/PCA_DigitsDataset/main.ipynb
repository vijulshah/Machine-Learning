{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Example using Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataset = load_digits()\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have images in dataset -> data with pixel values in 1D array. Let's convert it into 2D and view the Image (which will be a 2D matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eecdd3cd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dataset.data[0].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eecdb99250>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dataset.data[4].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eecdc88280>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dataset.data[47].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_0_0',\n",
       " 'pixel_0_1',\n",
       " 'pixel_0_2',\n",
       " 'pixel_0_3',\n",
       " 'pixel_0_4',\n",
       " 'pixel_0_5',\n",
       " 'pixel_0_6',\n",
       " 'pixel_0_7',\n",
       " 'pixel_1_0',\n",
       " 'pixel_1_1',\n",
       " 'pixel_1_2',\n",
       " 'pixel_1_3',\n",
       " 'pixel_1_4',\n",
       " 'pixel_1_5',\n",
       " 'pixel_1_6',\n",
       " 'pixel_1_7',\n",
       " 'pixel_2_0',\n",
       " 'pixel_2_1',\n",
       " 'pixel_2_2',\n",
       " 'pixel_2_3',\n",
       " 'pixel_2_4',\n",
       " 'pixel_2_5',\n",
       " 'pixel_2_6',\n",
       " 'pixel_2_7',\n",
       " 'pixel_3_0',\n",
       " 'pixel_3_1',\n",
       " 'pixel_3_2',\n",
       " 'pixel_3_3',\n",
       " 'pixel_3_4',\n",
       " 'pixel_3_5',\n",
       " 'pixel_3_6',\n",
       " 'pixel_3_7',\n",
       " 'pixel_4_0',\n",
       " 'pixel_4_1',\n",
       " 'pixel_4_2',\n",
       " 'pixel_4_3',\n",
       " 'pixel_4_4',\n",
       " 'pixel_4_5',\n",
       " 'pixel_4_6',\n",
       " 'pixel_4_7',\n",
       " 'pixel_5_0',\n",
       " 'pixel_5_1',\n",
       " 'pixel_5_2',\n",
       " 'pixel_5_3',\n",
       " 'pixel_5_4',\n",
       " 'pixel_5_5',\n",
       " 'pixel_5_6',\n",
       " 'pixel_5_7',\n",
       " 'pixel_6_0',\n",
       " 'pixel_6_1',\n",
       " 'pixel_6_2',\n",
       " 'pixel_6_3',\n",
       " 'pixel_6_4',\n",
       " 'pixel_6_5',\n",
       " 'pixel_6_6',\n",
       " 'pixel_6_7',\n",
       " 'pixel_7_0',\n",
       " 'pixel_7_1',\n",
       " 'pixel_7_2',\n",
       " 'pixel_7_3',\n",
       " 'pixel_7_4',\n",
       " 'pixel_7_5',\n",
       " 'pixel_7_6',\n",
       " 'pixel_7_7']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's feed the dataset.data in pandas as rows and dataset.feature_names as the columns, as they describe the pixel value in row_column name. Eg: pixel_row_column -> pixel_1_4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset.target tells the possible value of our digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, lets make a model which will be trained our digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we will reduce the feature pixels which will not be contributing in training out model. <br/>\n",
    "- Here, for example as you can see the image, left and right columns on the edges are completely black and have 0 values. Thus they will not be helpful or not be contibuting in our training. <br/>\n",
    "- So its better to remove such features from our datasets. This is called dimensionality reduction. PCA works on this principle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets see a model before applying PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ...,\n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will use PCA to reduce dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use components such that 95% of variance is retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Dimentionality Reduction =  (1797, 64)\n",
      "After Dimentionality Reduction =  (1797, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.95)\n",
    "print(\"Before Dimentionality Reduction = \",X.shape)\n",
    "\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(\"After Dimentionality Reduction = \",X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.25946645,  21.27488348,  -9.46305462, ...,   3.67072108,\n",
       "         -0.9436689 ,  -1.13250195],\n",
       "       [  7.9576113 , -20.76869896,   4.43950604, ...,   2.18261819,\n",
       "         -0.51022719,   2.31354911],\n",
       "       [  6.99192297,  -9.95598641,   2.95855808, ...,   4.22882114,\n",
       "          2.1576573 ,   0.8379578 ],\n",
       "       ...,\n",
       "       [ 10.8012837 ,  -6.96025223,   5.59955453, ...,  -3.56866194,\n",
       "          1.82444444,   3.53885886],\n",
       "       [ -4.87210009,  12.42395362, -10.17086635, ...,   3.25330054,\n",
       "          0.95484174,  -0.93895602],\n",
       "       [ -0.34438963,   6.36554919,  10.77370849, ...,  -3.01636722,\n",
       "          1.29752723,   2.58810313]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14890594, 0.13618771, 0.11794594, 0.08409979, 0.05782415,\n",
       "       0.0491691 , 0.04315987, 0.03661373, 0.03353248, 0.03078806,\n",
       "       0.02372341, 0.02272697, 0.01821863, 0.01773855, 0.01467101,\n",
       "       0.01409716, 0.01318589, 0.01248138, 0.01017718, 0.00905617,\n",
       "       0.00889538, 0.00797123, 0.00767493, 0.00722904, 0.00695889,\n",
       "       0.00596081, 0.00575615, 0.00515158, 0.0048954 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca.explained_variance_ratio_ this method tells us how much each feature is contributing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, lets see a model after applying PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694444444444444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_pca, y_train)\n",
    "model.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result 1: As you can see, there was not much reduction in accuracy of the model even after we removed some features (from 64 to 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what happens if we consider only 2 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.2594675 ,  21.27488399],\n",
       "       [  7.95760512, -20.76869215],\n",
       "       [  6.99192671,  -9.95598961],\n",
       "       ...,\n",
       "       [ 10.8012887 ,  -6.96025857],\n",
       "       [ -4.87209969,  12.42395542],\n",
       "       [ -0.34438061,   6.36553861]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14890594, 0.13618771])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see that both combined variances retains only 0.14 + 0.13 = 0.27 or 27% of important feature information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6083333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=30)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_pca, y_train)\n",
    "model.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result 2: As you can see, there is a significant reduction in accuracy of the model as we had only considered only 2 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Doing PCA many times reduces the accuracy but computation is much lighter and that's the trade off we need to consider while building models in real life"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d873d72b53a2e16f6509acf8aa60b8e127206db8f718c77de06c7675ff4739c6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
